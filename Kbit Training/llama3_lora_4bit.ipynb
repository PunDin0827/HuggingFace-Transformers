{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *載入模型和Tokenizer*"
      ],
      "metadata": {
        "id": "8jHZ0y64r9nJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caBVvDQM9tpe"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "KB0UKLK59zz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl\n",
        "# !pip install --upgrade bitsandbytes"
      ],
      "metadata": {
        "id": "pkOSc9YS_R2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "K98BS2iRpStA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset , load_dataset\n",
        "from transformers import (AutoTokenizer,\n",
        "              AutoModelForCausalLM,\n",
        "              DataCollatorForSeq2Seq,\n",
        "              TrainingArguments,\n",
        "              Trainer,\n",
        "              BitsAndBytesConfig,\n",
        "              pipeline,\n",
        "              logging,\n",
        "              TextStreamer)"
      ],
      "metadata": {
        "id": "RbRNaQD692OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig , PeftModel , get_peft_model , prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "import os , wandb"
      ],
      "metadata": {
        "id": "inAl3NBv-omV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.2-1B\""
      ],
      "metadata": {
        "id": "xPGHLDHb_i5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"scooterman/guanaco-llama3-1k\""
      ],
      "metadata": {
        "id": "knKVcyMy_rqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_use_double_quant=False)\n"
      ],
      "metadata": {
        "id": "cZNiDIyPAlLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                quantization_config=bnb_config,\n",
        "                # devize_map = {\"\":0}\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "A8T3fQwtDj_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "yzafgopEEHuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True #自動添加結束標記"
      ],
      "metadata": {
        "id": "f90lh_GtEM_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name , split = \"train\")\n",
        "dataset[\"text\"][0]"
      ],
      "metadata": {
        "id": "L7lfOh4xn_Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *wandb*"
      ],
      "metadata": {
        "id": "BVFOk8UFr4WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "wandb.login(key = \"\")"
      ],
      "metadata": {
        "id": "2GtmvUnDr7WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    project = \"test\",\n",
        "    job_type = \"train\"\n",
        ")"
      ],
      "metadata": {
        "id": "L-wy8vVXtUOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算參數數量\n",
        "def print_trainable_parameters(model):\n",
        "  trainable_params = 0\n",
        "  all_params = 0\n",
        "  for _ , param in model.named_parameters():\n",
        "    all_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "      trainable_params += param.numel()\n",
        "  print(\n",
        "      f\"訓練參數量:{trainable_params}||總共參數量:{all_params}||訓練參數占比:{100*(trainable_params / all_params):.2f}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "HUf7kACZuJ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *LoRA與訓練參數配置*"
      ],
      "metadata": {
        "id": "dgf9cVtXvc3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    r = 8,\n",
        "    lora_alpha = 16, # 可設定為r的兩倍\n",
        "    # scaling = alpha / r ,LoRA權重值越大影響越大\n",
        "    # weight += (lora_B @ lora_A) * scaling\n",
        "    lora_dropout = 0.05,\n",
        "    bias = \"none\",\n",
        "    task_type = \"CAUSAL_LM\",\n",
        "    target_modules = [\"q_proj\",\"v_proj\"]\n",
        ")"
      ],
      "metadata": {
        "id": "1nUpSA23vvc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir = \"./output\",\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = 4,\n",
        "    gradient_accumulation_steps = 2, # 梯度保存,2步更新一次\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    save_steps = 100,\n",
        "    logging_steps = 30,\n",
        "    learning_rate = 2e-4,\n",
        "    weight_decay = 0.001,\n",
        "    fp16 = False,\n",
        "    bf16 = False,\n",
        "    max_grad_norm = 0.3, # 最大梯度\n",
        "    max_steps = 1,\n",
        "    warmup_ratio = 0.3, # 前30%訓練步數會逐漸提高學習率\n",
        "    group_by_length = True, # 按序列長度分組,提高訓練效率\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    report_to = \"wandb\",\n",
        ")"
      ],
      "metadata": {
        "id": "ANOdbohTXDT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *模型微調*"
      ],
      "metadata": {
        "id": "NC8vkTP7ctZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = dataset,\n",
        "    peft_config = peft_config,\n",
        "    tokenizer = tokenizer,\n",
        "    dataset_text_field = \"text\",\n",
        "    args = training_arguments,\n",
        "    packing = False\n",
        ")"
      ],
      "metadata": {
        "id": "Y4nqxGuRcvvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *開始訓練*"
      ],
      "metadata": {
        "id": "-jWC8SbIeF8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "mP2ftHIUeH4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model , peft_config)\n",
        "\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtSmQI3ifZFf",
        "outputId": "04466e39-d991-4814-a792-623731dfa191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練參數量:851968||總共參數量:750127104||訓練參數占比:0.1135764852992167\n"
          ]
        }
      ]
    }
  ]
}