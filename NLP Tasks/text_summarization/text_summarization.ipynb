{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step.1 導入相關套件"
      ],
      "metadata": {
        "id": "WcPyRCeDF5HP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5I3vJXJEcP2"
      },
      "outputs": [],
      "source": [
        "!pip install rouge-chinese\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer , AutoModelForSeq2SeqLM , DataCollatorForSeq2Seq , Seq2SeqTrainer , Seq2SeqTrainingArguments"
      ],
      "metadata": {
        "id": "qmJ3QCmIGJU2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.2 載入數據*"
      ],
      "metadata": {
        "id": "0adwKHZWG0sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = Dataset.load_from_disk(\"./nlpcc_2017\")\n",
        "ds"
      ],
      "metadata": {
        "id": "dBuK9tTrGxrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.train_test_split(100 , seed=42)\n",
        "ds"
      ],
      "metadata": {
        "id": "gJ3_1LX0IBmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"][0]"
      ],
      "metadata": {
        "id": "1xb3EFmUIJEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.3 數據處理*"
      ],
      "metadata": {
        "id": "oi5iew7WISXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "fxrZG5hDIVFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_func(exmaples):\n",
        "    contents = [\"摘要生成: \\n\" + e for e in exmaples[\"content\"]]\n",
        "    inputs = tokenizer(contents, max_length= 384 , truncation=True)\n",
        "    labels = tokenizer(text_target=exmaples[\"title\"], max_length=64, truncation=True)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "hbYtn4dLIizI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = ds.map(process_func , batched=True)"
      ],
      "metadata": {
        "id": "7W-0oOq1J-Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenized_ds[\"train\"][0][\"input_ids\"])"
      ],
      "metadata": {
        "id": "ea8w4lPoKQFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenized_ds[\"train\"][0][\"labels\"])"
      ],
      "metadata": {
        "id": "8MibuIuSKxus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.4 建立模型*"
      ],
      "metadata": {
        "id": "yLJAwmd7K4dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Langboat/mengzi-t5-base\")"
      ],
      "metadata": {
        "id": "3zDjSdIYK6uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.5 評估函數*"
      ],
      "metadata": {
        "id": "jU3pHnIpK9wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from rouge_chinese import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "\n",
        "def compute_metric(evalPred):\n",
        "    predictions, labels = evalPred\n",
        "    decode_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
        "    decode_labels = [\" \".join(l) for l in decode_labels]\n",
        "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
        "    return {\n",
        "        \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
        "        \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
        "        \"rouge-l\": scores[\"rouge-l\"][\"f\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TODaRR40LDEJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.6 訓練參數*"
      ],
      "metadata": {
        "id": "WXibjeJcNSkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./summary\",\n",
        "    per_device_train_batch_size = 4,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    logging_steps = 8,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    metric_for_best_model = \"rouge-l\",\n",
        "    predict_with_generate=True\n",
        ")"
      ],
      "metadata": {
        "id": "TtcWWXDbNU8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.7 訓練器*"
      ],
      "metadata": {
        "id": "_pEUXEG-OVTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    args = args,\n",
        "    model = model,\n",
        "    train_dataset = tokenized_ds[\"train\"],\n",
        "    eval_dataset = tokenized_ds[\"test\"],\n",
        "    compute_metrics = compute_metric,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
        ")"
      ],
      "metadata": {
        "id": "gGFGckVEOXk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.8 模型訓練*"
      ],
      "metadata": {
        "id": "uR5jR-qEPCM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "kgn1cet9PEhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.9 模型推理*"
      ],
      "metadata": {
        "id": "kL52sQCDPGeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "2o5BUSiEPKww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)"
      ],
      "metadata": {
        "id": "Tmyq0NabPLfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"摘要生成:\\n\" + ds[\"test\"][-1][\"content\"], max_length=64, do_sample=True)"
      ],
      "metadata": {
        "id": "QIb-SPJkPMl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"test\"][-1][\"title\"]"
      ],
      "metadata": {
        "id": "dMqc7pRsPOaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}