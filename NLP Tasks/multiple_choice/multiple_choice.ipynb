{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Step.1 載入相關套件*"
      ],
      "metadata": {
        "id": "CJEWtok3JE61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "mAfbty2oJPUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t16Bz9MoGX0q"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "from datasets import Dataset , DatasetDict\n",
        "from transformers import AutoTokenizer , AutoModelForMultipleChoice , Trainer , TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.2 載入數據*"
      ],
      "metadata": {
        "id": "4RjGIl0lJwh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c3 = DatasetDict.load_from_disk(\"./c3\")\n",
        "c3"
      ],
      "metadata": {
        "id": "-It8QeOdJ29G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c3[\"train\"][0]"
      ],
      "metadata": {
        "id": "IlJON4rIKGbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c3.pop(\"test\")"
      ],
      "metadata": {
        "id": "hMYTfqjfKVQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c3"
      ],
      "metadata": {
        "id": "aJovioRfKZn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.3 數據預處理*"
      ],
      "metadata": {
        "id": "n2xf614FKcxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "jngD_gsKKbRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_function(examples):\n",
        "    # examples, dict, keys: [\"context\", \"quesiton\", \"choice\", \"answer\"]\n",
        "    # examples, 1000\n",
        "    context = []\n",
        "    question_choice = []\n",
        "    labels = []\n",
        "    for idx in range(len(examples[\"context\"])):\n",
        "        ctx = \"\\n\".join(examples[\"context\"][idx])\n",
        "        question = examples[\"question\"][idx]\n",
        "        choices = examples[\"choice\"][idx]\n",
        "        for choice in choices:\n",
        "            context.append(ctx)\n",
        "            question_choice.append(question + \" \" + choice)\n",
        "        if len(choices) < 4:\n",
        "            for _ in range(4 - len(choices)):\n",
        "                context.append(ctx)\n",
        "                question_choice.append(question + \" \" + \"不知道\")\n",
        "        labels.append(choices.index(examples[\"answer\"][idx]))\n",
        "    tokenized_examples = tokenizer(context, question_choice, truncation=\"only_first\", max_length=256, padding=\"max_length\")     # input_ids: 4000 * 256,\n",
        "    tokenized_examples = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}     # 1000 * 4 *256\n",
        "    tokenized_examples[\"labels\"] = labels\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "XeM1hOqWLpZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = c3[\"train\"].select(range(10)).map(process_function, batched=True)\n",
        "res"
      ],
      "metadata": {
        "id": "6KRtXvhCRXW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(res[\"input_ids\"]).shape"
      ],
      "metadata": {
        "id": "pCutgOkhSWgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_c3 = c3.map(process_function, batched=True)\n",
        "tokenized_c3"
      ],
      "metadata": {
        "id": "rkvUXXPuTGaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.4 模型建立*"
      ],
      "metadata": {
        "id": "hmSTrX_STKGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForMultipleChoice.from_pretrained(\"hfl/chinese-macbert-base\")"
      ],
      "metadata": {
        "id": "s6cjwOY5TNZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.5 評估函數*"
      ],
      "metadata": {
        "id": "WQHdX6KmUZ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metric(pred):\n",
        "    predictions, labels = pred\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "5NjoRXeQUZnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.6 訓練參數*"
      ],
      "metadata": {
        "id": "f18DdcU3Wgw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir = \"./multiple_choice\",\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 16,\n",
        "    num_train_epochs = 3,\n",
        "    logging_steps =50,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    load_best_model_at_end= True ,\n",
        "    fp16 = True\n",
        ")"
      ],
      "metadata": {
        "id": "v-Uy5CQTWgdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.7 訓練器*"
      ],
      "metadata": {
        "id": "vX2J5ohFZPnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = args,\n",
        "    train_dataset = tokenized_c3[\"train\"],\n",
        "    eval_dataset = tokenized_c3[\"validation\"],\n",
        "    compute_metrics = compute_metric\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "8wZRRAdkZTQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.8 模型訓練*"
      ],
      "metadata": {
        "id": "HC_uh85SaJVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "k2C_ks-2aHHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step.9 模型預測*"
      ],
      "metadata": {
        "id": "w2R7S6_-aw1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "import torch\n",
        "\n",
        "class MultiplePieline:\n",
        "\n",
        "  def __init__(self, model , tokenizer) -> None:\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.device = model.device\n",
        "\n",
        "  def preprocess(self , context , question , choices):\n",
        "    cs , qcs = [],[]\n",
        "    for choice in choices:\n",
        "      cs.append(context)\n",
        "      qcs.append(question + \" \" + choice)\n",
        "    return tokenizer(cs , qcs ,truncation = \"only_first\" , max_length = 256 , return_tensors=\"pt\")\n",
        "\n",
        "  def predict(self , inputs):\n",
        "    inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
        "    return self.model(**inputs).logits\n",
        "\n",
        "  def postprocess(self , logits , choices):\n",
        "    predition = torch.argmax(logits, dim=-1).cpu().item()\n",
        "    return choices[predition]\n",
        "\n",
        "\n",
        "  def __call__(self, context , question , choices) -> Any:\n",
        "     inputs = self.preprocess(context , question , choices)\n",
        "     logits = self.predict(inputs)\n",
        "     result = self.postprocess(logits , choices)\n",
        "     return result"
      ],
      "metadata": {
        "id": "XTNfHOGgazbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = MultipleChoicePipeline(model, tokenizer)"
      ],
      "metadata": {
        "id": "hJDq3tcHex2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"小明在北京上班\",\"小明在哪裡上班?\",[\"北京\",\"上海\"])"
      ],
      "metadata": {
        "id": "ZFHcsX2vezhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}